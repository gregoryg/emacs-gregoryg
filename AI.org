#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:nil
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:nil todo:t |:t
#+TITLE: AI / LLM Configuration and Experimentation in Org-Mode
#+DATE: <2026-01-29 Thu>
#+AUTHOR: Greg Grubbs
#+EMAIL: gregory.grubbs@gmail.com
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+setupfile: ~/projects/emacs/org-themes/src/readtheorg_inline/readtheorg_inline.theme

#+property: header-args:emacs-lisp :tangle ~/.emacs.d/emacs-ai-llm.el :results none
#+property: header-args:bash :comments both :shebang #!/usr/bin/env bash :results none

* AI / LLM interaction
** Set lexical binding cookie in tangled file
   #+begin_src emacs-lisp :comments no 
     ;;; ...  -*- lexical-binding: t -*-
   #+end_src
** Support Skills a la Anthropic
   #+begin_src bash :results verbatim :tangle ~/bin/list-skills-metadata.sh :shebang #!/usr/bin/env bash
     skillsdir=$1

     if [ -z "${skillsdir}" ]; then
         echo "No skill directory was given"
         exit 1
     else
         echo "My list of available skills for this session:"
         for skillfile in "${skillsdir}/"*/SKILL.md
         do
             if [ -a "${skillfile}" ]; then
                 head -5 "${skillfile}" | grep -E '^(name:|description:)'
                 echo "location: ${skillfile}"
                 echo "============="
             fi
         done
     fi
   #+end_src

** mcp.el - Model Context Protocol
*** Configure MCP servers
   #+begin_src emacs-lisp
     (add-to-list 'load-path "~/projects/emacs/ai/mcp.el")
     (require 'mcp-hub)

     (setq mcp-hub-servers
           `(
             ("filesystem" . (:command "npx"
                                       :args
                                       ("-y" "@modelcontextprotocol/server-filesystem"
             ("rubber-duck" . (:command "node"
                                        :args ("/home/gregj/projects/ai/ModelContextProtocol/mcp-rubber-duck/dist/index.js")
                                        :env (
                                              :MCP_SERVER "true"
                                                          :OPENAI_API_KEY ,(gjg/authinfo-secret "api.openai.com")
                                                          :OPENAI_DEFAULT_MODEL "gpt-5.2"
                                                          :GEMINI_API_KEY ,(gjg/authinfo-secret "generativelanguage.googleapis.com")
                                                          :GEMINI_DEFAULT_MODEL "gemini-3-pro-preview"
                                                          :CUSTOM_ANTHROPIC_API_KEY ,(gjg/authinfo-secret "openrouter.ai")
                                                          :CUSTOM_ANTHROPIC_BASE_URL "https://openrouter.ai/api/v1"
                                                          :CUSTOM_ANTHROPIC_DEFAULT_MODEL "anthropic/claude-opus-4.5"
                                                          :CUSTOM_ANTHROPIC_NICKNAME "Anthropic Opus 4.5 via OpenRouter"
                                                          :CUSTOM_GROK_API_KEY ,(gjg/authinfo-secret "openrouter.ai")
                                                          :CUSTOM_GROK_BASE_URL "https://openrouter.ai/api/v1"
                                                          :CUSTOM_GROK_DEFAULT_MODEL "x-ai/grok-4"
                                                          :CUSTOM_GROK_NICKNAME "Grok Shmok via OpenRouter"
                                                          :MCP_BRIDGE_ENABLED "true"
                                                          :MCP_SERVER_BRAVESEARCH_TYPE "stdio"
                                                          :MCP_SERVER_BRAVESEARCH_COMMAND "python"
                                                          :MCP_SERVER_BRAVESEARCH_ARGS "/blah"
                                                          :MCP_SERVER_BRAVESEARCH_ENABLED "false"

                                                          :DEFAULT_PROVIDER "openai"
                                                          :LOG_LEVEL "info")
                                        :timeout 600))
             ;; web search - uses API key
             ("brave-search" . (:command "npx"
                                         :args ("-y" "@modelcontextprotocol/server-brave-search")
                                         :env (:BRAVE_API_KEY ,(gjg/authinfo-secret "brave-search-key"))))
             ("github" . (:command "podman"
                                   :args ("run"
                                          "--name" "github-mcp"
                                          "--interactive"
                                          "--rm"
                                          "--env"
                                          "GITHUB_PERSONAL_ACCESS_TOKEN"
                                          "ghcr.io/github/github-mcp-server")
                                   :env (:GITHUB_PERSONAL_ACCESS_TOKEN ,(gjg/authinfo-secret "mcp-server-github" "gregoryg"))))

             ("private-journal" . (:command "npx"
                                            :args ("github:obra/private-journal-mcp")))
             ("memory" . (:command "npx"
                                   :args ("-y" "@modelcontextprotocol/server-memory")))

             ;; PSA: keep the "everything" server commented to avoid getting *Messages* buffer spammed
             ;; ("everything" . (:command "npx"
             ;;                           :args
             ;;                           ("-y" "@modelcontextprotocol/server-everything")))
             ;; see https://github.com/neo4j-contrib/mcp-neo4j/?tab=readme-ov-file
             ;; ("neo4j" . (:command "uvx"
             ;;                      :args
             ;;                      ("mcp-neo4j-memory@0.1.3"
             ;;                       "--db-url"
             ;;                       "neofj+s://xxx.databases.neo4j.io"
             ;;                       "--username"
             ;;                       "<your-username>"
             ;;                       "--password"
             ;;                       "<your-password>")))
             ;; see https://github.com/neo4j-contrib/mcp-neo4j/tree/main/servers/mcp-neo4j-cypher

             ;; Terminal / shell commands
             ("mcp-shell-server" . (:command "uvx"
                                             :args ("mcp-shell-server")
                                             :env (:ALLOW_COMMANDS "bc,cat,chmod,curl,date,echo,emacs,find,git,grep,gunzip,head,jq,kubectl,ls,lynx,npm,psql,pwd,python,rg,sed,sqlite3,tail,unzip,wc")))
             ("mariadb-readonly" . (:command "uvx"
                                             :args ("mcp-server-mariadb" "--host" "protomolecule.magichome" "--port" "3306" "--user" "gregj" "--password" ,(gjg/authinfo-secret "homelab-mysql" "gregj") "--database" "teslafi")))
             ("movies-neo4j" . (:command "uvx"
                                         :args ("mcp-neo4j-cypher@0.2.1")
                                         :env (
                                               :NEO4J_URI "neo4j+s://demo.neo4jlabs.com"
                                               :NEO4J_USERNAME "recommendations"
                                               :NEO4J_PASSWORD "recommendations"
                                               :NEO4J_DATABASE "recommendations")))
             ("playwright" . (:command "npx"
                                       :args ("-y" "@executeautomation/playwright-mcp-server")))
             ("chrome-devtools" . (:command "npx"
                                            :args ("chrome-devtools-mcp@latest")))
             ("terminal-controller" . (:command "uvx"
                                                :args ("terminal_controller")))

             ("travel-planner" . (:command "npx"
                                           :args ("@gongrzhe/server-travelplanner-mcp")
                                           :env (:GOOGLE_MAPS_API_KEY ,(gjg/authinfo-secret "api.googlemaps.travel-planner.key"))))
             ("ha-mcp" .  (:command "uvx"
                                    :args ("--refresh" "ha-mcp@latest")
                                    :env (:HOMEASSISTANT_URL "http://172.16.17.7:8123"
                                          :HOMEASSISTANT_TOKEN ,(gjg/authinfo-secret "ha-mcp-token"))))
             ))
#+end_src

** GPTEL - LLMs in Markdown and Org Mode

  + [X] TODO: add completing-read with marginalia for =gptel-directives= (named prompts)
  + [ ] TODO: indicate system prompt(s) and model(s) used in *gpt-mode* buffer
  + ref: [[https://github.com/karthink/gptel][karthink/gptel: A no-frills ChatGPT client for Emacs ≫ github.com]] This package
    has it all: auth-source, Org Mode buffers, Markdown mode or other-mode buffers if
    you prefer, named prompts for special occasions, a transient mode interface, model
    choice, temperature settings, streaming support, multiple APIs, multiple chat
    sessions, an active GitHub. A dedication to keeping everything in plain text
    (without metadata markup)

*** Load gptel using straight.el with my fork
   Because I want to augment, tweak and contribute to this package, I tell
   =straight-use-package= to pull from my fork and my =gregoryg= branch.

   #+begin_src emacs-lisp
     ;; (straight-use-package
     ;;  '(gptel :type git :host github :repo "karthink/gptel"
     ;;          :fork (:host github :branch "gregoryg" :repo "gregoryg/gptel")))

     ;; Use :nonrecursive to avoid straight.el's mishandling of submodules - the only submodule used is 'test'
     ;; see https://github.com/karthink/gptel/issues/716
     (use-package gptel
       :straight (:host github :repo "karthink/gptel" :nonrecursive t))
     ;; (use-package gptel :straight t)
     (custom-set-variables '(gptel-default-mode 'org-mode)
                           '(gptel-expert-commands t)
                           '(gptel-track-media t)
                           '(gptel-include-reasoning 'ignore)
                           '(gptel-model 'gpt-4o)
                           '(gptel-log-level 'info)
                           '(gptel--debug nil))
     ;; add-to-list instead of setf for alists https://emacs.stackexchange.com/a/3402/418
     (add-to-list 'gptel-prompt-prefix-alist `(org-mode . ,(concat "*** gjg " (format-time-string "[%Y-%m-%d]") "\n")))
     ;; defer nothing
     (require 'gptel)
     ;; (require 'gptel-transient)
     (require 'gptel-integrations)
   #+end_src
*** Load jwiegley/gptel-prompts for prompt composability
    #+begin_src emacs-lisp :tangle no
      (use-package gptel-prompts
        :straight nil
        :load-path "~/projects/emacs/ai/gptel-prompts"
        :after (gptel)
        :demand t
        :config
        (custom-set-variables '(gptel-prompts-directory "~/projects/ai/AIPIHKAL/composable-prompts"))
        (gptel-prompts-update)
        ;; ensure prompts are updated if prompt files change
        (gptel-prompts-add-update-watchers))

      ;; '(sparql-mode :type git :host github :repo "jwiegley/gptel-prompts"
      ;; :fork (:host github :branch "main" :repo "gregoryg/gptel-prompts")

#+end_src
*** Create custom Together.AI backend
    This makes use of the [[https://docs.together.ai/docs/openai-api-compatibility][OpenAI-compatible API]], which makes the backend generation super simple!
**** Model capabilities
     It's difficult to find model capabilities on the models' pages instead.  Try looking in these areas
***** Tool use
      [[https://docs.together.ai/docs/function-calling#supported-models][Function Calling - Together.ai Docs ≫ docs.together.ai]]
***** JSON structred output

    [[https://docs.together.ai/docs/json-mode#supported-models][Structured Outputs - Together.ai Docs ≫ docs.together.ai]]

     #+begin_src emacs-lisp
       (gptel-make-openai ; but for Togeher.AI compatible API
        "together.ai"
        :header (lambda () `(("Authorization" . ,(concat "Bearer " (gptel--get-api-key )))))
        :key gptel-api-key
        :stream t
        :host "api.together.xyz"
        :protocol "https"
        :endpoint "/v1/chat/completions"
        :models '((openai/gpt-oss-120b
                   :description "OpenAI OSS 120b parameter model"
                   :capabilities (tool json url)
                   :input-cost 0.15 :output-cost 0.60)
                  (zai-org/GLM-4.5-Air-FP8
                   :description "The GLM-4.5 series models are foundation models designed for intelligent agents. GLM-4.5 has 355 billion total parameters with 32 billion active parameters, while GLM-4.5-Air adopts a more compact design with 106 billion total parameters and 12 billion active parameters. GLM-4.5 models unify reasoning, coding, and intelligent agent capabilities to meet the complex demands of intelligent agent applications."
                   :capabilities (tool json url)
                   :input-cost 0.20 :output-cost 1.10)
                  (moonshotai/Kimi-K2-Instruct
                   :capabilities (tool json url)
                   :input-cost 1.00 :output-cost 3.00)
                  (Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8
                   :capabilities (tool json url)
                   :input-cost 2.00 :output-cost 2.00)
                  Qwen/Qwen3-235B-A22B-fp8-tput
                  codellama/CodeLlama-70b-Instruct-hf
                  tiiuae/falcon-40b-instruct
                  codellama/CodeLlama-34b-Instruct-hf
                  deepseek-ai/DeepSeek-R1
                  deepseek-ai/DeepSeek-V3
                  mistralai/Mixtral-8x7B-Instruct-v0.1
                  mistralai/Mixtral-8x22B-Instruct-v0.1
                  meta-llama/llama-2-70b-chat-hf
                  meta-llama/Llama-3-70b-chat-hf
                  meta-llama/Llama-3.3-70B-Instruct-Turbo
                  meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                  microsoft/WizardLM-2-8x22B
                  ))
     #+end_src
*** Configure Openrouter
    #+begin_src emacs-lisp
      (gptel-make-openai "OpenRouter"
        :stream t
        :host "openrouter.ai"
        :endpoint "/api/v1/chat/completions"
        :key #'gptel-api-key
        :models '(
                  (anthropic/claude-opus-4.5
                   :description "Claude Opus 4.5 is Anthropic’s frontier reasoning model optimized for complex software engineering, agentic workflows, and long-horizon computer use. It offers strong multimodal capabilities, competitive performance across real-world coding and reasoning benchmarks, and improved robustness to prompt injection. The model is designed to operate efficiently across varied effort levels, enabling developers to trade off speed, depth, and token usage depending on task requirements. It comes with a new parameter to control token efficiency, which can be accessed using the OpenRouter Verbosity parameter with low, medium, or high.

      Opus 4.5 supports advanced tool use, extended context management, and coordinated multi-agent setups, making it well-suited for autonomous research, debugging, multi-step planning, and spreadsheet/browser manipulation. It delivers substantial gains in structured reasoning, execution reliability, and alignment compared to prior Opus generations, while reducing token overhead and improving performance on long-running tasks."
                   :capabilities (media tool json url)
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 5.00 :output-cost 25.00)
                  (anthropic/claude-sonnet-4.5
                   :description " Anthropic’s most advanced Sonnet model to date, optimized for real-world agents and coding workflows."
                   :capabilities (media tool json url)
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 3.00 :output-cost 15.00)
                  (anthropic/claude-haiku-4.5
                   :description " Anthropic’s fastest and most efficient model, delivering near-frontier intelligence at a fraction of the cost and latency of larger Claude models."
                   :capabilities (media tool json url)
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 1.00 :output-cost 5.00)
                  (openai/gpt-oss-120b
                   :description "gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE) language model from OpenAI designed for high-reasoning, agentic, and general-purpose production use cases. It activates 5.1B parameters per forward pass and is optimized to run on a single H100 GPU with native MXFP4 quantization. The model supports configurable reasoning depth, full chain-of-thought access, and native tool use, including function calling, browsing, and structured output generation."
                   :capabilities (media tool json url)
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 0.09  :output-cost 0.45)
                  (openai/gpt-5-mini
                   :description "GPT-5 Mini is a compact version of GPT-5, designed to handle lighter-weight reasoning tasks. It is the successor to o4-mini"
                   :capabilities (media tool json url)
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 0.25 :output-cost 2)
                  (openai/gpt-5
                   :description "THE MEGILLAH"
                   :capabilities (media tool json url)
                   :mime-types
                   ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 1.25 :output-cost 10)
                  (deepseek/deepseek-chat-v3.1
                   :description "DeepSeek-V3.1 is a large hybrid reasoning model (671B parameters, 37B active) that supports both thinking and non-thinking modes via prompt templates. It extends the DeepSeek-V3 base with a two-phase long-context training process, reaching up to 128K tokens, and uses FP8 microscaling for efficient inference. Users can control the reasoning behaviour with the reasoning enabled boolean. Learn more in our docs

      The model improves tool use, code generation, and reasoning efficiency, achieving performance comparable to DeepSeek-R1 on difficult benchmarks while responding more quickly. It supports structured tool calling, code agents, and search agents, making it suitable for research, coding, and agentic workflows."
                   :capabilities (media tool json url)
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 0.55 :output-cost 1.66)
                  (qwen/qwen3-coder
                   :description "Qwen3-Coder-480B-A35B-Instruct is a Mixture-of-Experts (MoE) code generation model developed by the Qwen team. It is optimized for agentic coding tasks such as function calling, tool use, and long-context reasoning over repositories. The model features 480 billion total parameters, with 35 billion active per forward pass (8 out of 160 experts)."
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 0.45 :output-cost 1.50)
                  (moonshotai/kimi-k2
                   :description "Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass. It is optimized for agentic capabilities, including advanced tool use, reasoning, and code synthesis. Kimi K2 excels across a broad range of benchmarks, particularly in coding (LiveCodeBench, SWE-bench), reasoning (ZebraLogic, GPQA), and tool-use (Tau2, AceBench) tasks. It supports long-context inference up to 128K tokens and is designed with a novel training stack that includes the MuonClip optimizer for stable large-scale MoE training."
                   :mime-types ("image/jpeg" "image/png" "image/gif" "image/webp")
                   :input-cost 0.60 :output-cost 2.50)
                  openrouter/auto
                  google/gemini-2.0-flash-lite-preview-02-05:free
                  deepseek/deepseek-r1:free deepseek/deepseek-chat:free
                  z-ai/glm-4.5
                  google/gemini-2.5-pro
                  anthropic/claude-sonnet-4
                  ))
#+end_src
*** Configure Anthropic Claude

      #+begin_src emacs-lisp :tangle no
        (gptel-make-anthropic "Anthropic"
          :stream t
          :key gptel-api-key)
      #+end_src

*** Optionally modify OpenAI setup

    If OpenAI makes new models available, the package may lag behind - so specify what models you want to use here

     #+begin_src emacs-lisp :tangle no
       ;; do this by overriding var `gptel--openai'
       (setq gptel--openai
             (gptel-make-openai
                 "ChatGPT"
               :key 'gptel-api-key
               :stream t
               :models '(gpt-4o-mini
                         gpt-4o)))
     #+end_src
*** Add Ollama backend if Ollama API server is accessible
    This queries all installed models

     #+begin_src emacs-lisp
       (setq gjg/ollama-api-endpoint "http://172.16.17.77:11434")
       (defun gjg/get-ollama-models ()
         "Return a list of Ollama models from the API, or nil if the API is not available."
         (when-let*
             ((url (url-generic-parse-url gjg/ollama-api-endpoint))
              (host (url-host url))
              (port (url-port url))
              ;; Use short timeout with curl to assure API port is open
              (maybe-ollama-models (s-split "\n"
                                            (shell-command-to-string (concat "curl -s --connect-timeout 0.5 '"
                                                                             gjg/ollama-api-endpoint "/api/tags' | jq -r '.models[].name'"))))
              (my-ollama-models (seq-filter (lambda (s) (not (string= s "")))
                                            maybe-ollama-models)))
           (gptel-make-ollama
            "Ollama"
            :host (concat host ":" (number-to-string port))
            :models my-ollama-models
            :stream nil)
           my-ollama-models))

       ;; set globally, as ollama-models is relevant to more than gptel
       (setq ollama-models (gjg/get-ollama-models))

       ;; if API port was not found, remove backend
       (unless ollama-models
         (setq gptel--known-backends
               (assoc-delete-all "Ollama" gptel--known-backends #'equal)))
     #+end_src
*** Add Ollama as OpenAI API
    Ollama supports OpenAI-compatible API for LLMs as of [2024-02-13 Tue]

    So let's use that
    #+begin_src emacs-lisp :tangle no
      (when ollama-models  ;; set in previous code
        (gptel-make-openai ; but for Ollama's newer compatible API
            "ollama-compatible"
          ;; :header (lambda () `(("Authorization" . ,(concat "Bearer " (gptel--get-api-key )))))
          ;; :key gptel-api-key
          :stream t
          :host "172.16.17.77:11434"
          :protocol "http"
          :endpoint "/v1/chat/completions"
          :models ollama-models))
    #+end_src
*** Add Google Gemini
    + [[https://aistudio.google.com/app/apikey][API keys ≫ aistudio.google.com]]
    #+begin_src emacs-lisp
      (gptel-make-gemini
          "google-gemini"
        :stream t
        :key 'gptel-api-key)
        ;; :models '("gemini-pro" "gemini-1.5-pro-latest" "gemini-1.5-flash"))
    #+end_src
*** Load my custom system prompts (directives)
    This makes use of my AIPIKHAL package (AI Prompts I Have Known And Loved)
    #+begin_src emacs-lisp
      ;; Use the system prompt builder function
      (let ((build-directives-fun "~/projects/ai/AIPIHKAL/gptel-build-directives.el"))
        (when (f-exists-p build-directives-fun)
          (load build-directives-fun)
          ;; (custom-set-variables '(gptel-directives
          (setq gptel-directives (gjg/gptel-build-directives "~/projects/ai/AIPIHKAL/system-prompts/")
                gptel-system-message (alist-get 'default gptel-directives))))
    #+end_src
*** An experiment in composable prompts using presets
    Let's make a list of all directories that prompts may be found in - note that this is a subset of the =gptel-prompts= package by @jwiegley that I only discovered today [2025-07-03 Thu], but it suits my needs.

    We have a function that will work with 2 streams in my AIPIHKAL project
    #+begin_src emacs-lisp :tangle no
      (defcustom gjg/prompt-segment-directories
        '("~/projects/ai/AIPIHKAL/composable-prompts/" "~/projects/ai/AIPIHKAL/system-prompts")
        "A list of directories to search for gptel prompt segments.
      The search is performed in the order of the directories in this list."
        :type '(repeat string)
        :group 'gptel)

      (defun gjg/find-prompt-file (slug)
        "Find the full path for a prompt segment SLUG.

      Searches in =gjg/prompt-segment-directories= for a file that
      matches the SLUG. The filename may be prefixed with numbers (e.g.,
      \"00-\") and have an extension of .org, .md, or .txt.

      For example, the slug \"roles\" could match
      \"~/path/to/prompts/00-roles.org\".

      If multiple files match, a warning is issued and the first found
      file is returned."
        ;; Use =cl-loop= to concisely search across multiple directories.
        (let ((found-files
               (cl-loop for dir in gjg/prompt-segment-directories
                        for expanded-dir = (expand-file-name dir)
                        when (file-directory-p expanded-dir)
                        nconc (cl-loop for file in (directory-files expanded-dir)
                                       for full-path = (expand-file-name file expanded-dir)
                                       ;; Construct a regexp to find files like '00-slug.org'
                                       when (string-match-p
                                             (format "\\(?:[0-9]+-\\)?%s\\.\\(org\\|md\\|txt\\)\\'"
                                                     (regexp-quote slug))
                                             file)
                                       collect full-path))))

          (when (> (length found-files) 1)
            (warn "Found multiple files for slug '%s': %s. Using the first one."
                  slug found-files))

          (car found-files)))

      (defun gjg/build-system-prompt (slugs)
        "Build a system prompt by concatenating files matching SLUGS.

      For each slug in the list SLUGS, this function finds a
      corresponding prompt file using =gjg/find-prompt-file=,
      reads its content, and concatenates all contents together,
      separated by double newlines for clarity."
        (let* ((files (mapcar #'gjg/find-prompt-file slugs))
               (valid-files (cl-remove-if-not #'identity files))
               (contents (mapcar #'f-read-text valid-files)))
          (mapconcat #'identity contents "\n\n")))

#+end_src
*** Python coder
    #+begin_src emacs-lisp :tangle no
      (gptel-make-preset 'python-coder
        :description "Full prompt for a python coder partner."
        :system (gjg/build-system-prompt
                 '("roles" "use-org-mode" "project-context" "documentation" "task-management" "tool-usage" "code-structure" "coding-behavior-rules" "human-coding-partner" "python-style-conventions" "python-tests")))
#+end_src
*** Add my supplemental functions
**** Functions to use in hooks
***** Return Gptel backend + model
      I find it useful to indicate model and provider service (OpenAI, ollama, together.ai etc) at the beginning of each LLM response.
      #+begin_src emacs-lisp
        (defun gjg/gptel-backend-and-model ()
          "Return gptel backend and model (if any)."
          (let ((backend (if  (boundp 'gptel-backend)  (aref gptel-backend 1)))
                (model (if  (boundp 'gptel-model) gptel-model)))
            (format "%s %s" backend model)))
      #+end_src
***** Insert backend+model as first string in a response buffer
      This function is added as a hook to use with non-chat buffers.  In my org-mode chat buffers, I handle the model attribution differently (as part of my markdown->org function).
      #+begin_src emacs-lisp
        ;; (advice-add 'gptel-send :before #'org-timer-start)

        (defun gjg/gptel-insert-model-in-non-gptel-buffers ()
          "This function will add the backend and model in the \"dynamic\" buffers, not in dedicated chat buffers.
        To be used in `gptel-pre-response-hook'."
          (unless (member 'gptel-mode local-minor-modes)
            (goto-char (point-max))
            (insert (format "\n%s: " (gjg/gptel-backend-and-model)))
            (goto-char (point-max))))
        (add-hook 'gptel-pre-response-hook 'gjg/gptel-insert-model-in-non-gptel-buffers)

        (defun gjg/gptel-insert-model-in-chat-buffers (response-begin-pos response-end-pos)
          "This function adds the backend and model in dedicated chat buffers.
        Can be used with the `gptel-post-response-functions' hook."
          (let* ((gptel-org-prefix (alist-get 'org-mode gptel-prompt-prefix-alist))
                 (elapsed-time (org-timer nil t))
                 (inserted-string (format "%s %s (%s)\n"
                                          (substring gptel-org-prefix 0 (string-match " " gptel-org-prefix))
                                          (gjg/gptel-backend-and-model)
                                          (if (not (string= "0:00:00 " elapsed-time)) elapsed-time "" )))
                 (len-inserted (length inserted-string )))
            (goto-char response-begin-pos)
            (insert inserted-string)
            (goto-char (+ response-end-pos len-inserted)))
          (org-timer-stop))

        (add-hook 'gptel-post-response-functions 'gjg/gptel-insert-model-in-chat-buffers)
      #+end_src
***** Add a very long buffer-specific timout for mcp.el
      mcp.el/mcp-hub does not alter the default jsonrpc timeout of 10 seconds.  So if any mcp call takes more than 10 seconds to return, we end up with a hung tool call

      One area where this bites us in the collective arse is when using thinking LLMs in MCP calls (as with mcp-rubber-duck).

      So ... let's make a buffer-local substantial modification to the global default timeout of 10 seconds!

      #+begin_src emacs-lisp :tangle no
        (add-hook 'gptel-mode-hook
                  (lambda ()
                    (setq-local jsonrpc-default-request-timeout 600))) ;; 10 minutes, just to be safe
      #+end_src

**** Convert Markdown LLM responses to Org Mode using Pandoc
     This ultimately replaces the Markdown -> Org Mode conversion built in to =gptel=

     #+begin_src emacs-lisp :tangle no
       ;; pandoc -f gfm -t org|sed '/:PROPERTIES:/,/:END:/d'

       (defun gjg/gptel--convert-markdown->org (str)
         "Convert string STR from markdown to org markup using Pandoc.
         Remove the property drawers Pandoc insists on inserting for org output."
         ;; point will be at the last user position - assistant response will be after that to the end of the buffer (hopefully without the next user prompt)
         ;; So let's
         (interactive)
         (let* ((org-prefix (alist-get 'org-mode gptel-prompt-prefix-alist))
                (shift-indent (progn (string-match "^\\(\\*+\\)" org-prefix) (length (match-string 1 org-prefix))))
                (lua-filter (when (file-readable-p "~/.config/pandoc/gfm_code_to_org_block.lua")
                              (concat "--lua-filter=" (expand-file-name "~/.config/pandoc/gfm_code_to_org_block.lua"))))
                (temp-name (make-temp-name "gptel-convert-" ))
                (sentence-end "\\([.?!
         ]\\)"))
           ;; TODO: consider placing original complete response in the kill ring
           ;; (with-temp-buffer
           (with-current-buffer (get-buffer-create (concat "*" temp-name "*"))
             (insert str)
             (write-region (point-min) (point-max) (concat "/tmp/" temp-name ".md" ))
             (shell-command-on-region (point-min) (point-max)
                                      (format "pandoc -f gfm -t org --shift-heading-level-by=%d %s|sed '/:PROPERTIES:/,/:END:/d'" shift-indent lua-filter)
                                      nil ;; use current buffer
                                      t   ;; replace the buffer contents
                                      "*gptel-convert-error*")
             (goto-char (point-min))
             (insert (format "%sLLM %s: \n"
                             (alist-get 'org-mode gptel-prompt-prefix-alist)
                             (gjg/gptel-backend-and-model)))
             (goto-char (point-max))
             (buffer-string))))

       (defun gjg/gptel-convert-org-with-pandoc (content buffer)
         "Transform CONTENT acoording to required major-mode using `pandoc'.
          Currenly only `org-mode' is supported
          This depends on the `pandoc' binary only, not on the  Emacs Lisp `pandoc' package."
         (pcase (buffer-local-value 'major-mode buffer)
           ('org-mode (gjg/gptel--convert-markdown->org content))
           (_ content)))

       ;; (custom-set-variables '(gptel-response-filter-functions
       ;;                         '(gjg/gptel-convert-org-with-pandoc)))
     #+end_src
**** Possibly useful function: insert cleaned text from URL into buffer
     #+begin_src emacs-lisp
       (defun gjg/insert-clean-website-text (url)
         "Run a shell command to return clean body text from the given URL."
         (interactive)
         (if (executable-find "text-from-url.py")
             (insert (shell-command-to-string (concat "text-from-url.py " url)))
           (message "Command not found: text-from-url.py")
           )
         )
     #+end_src
*** Custom functions leveraging gptel
   TODO: check out [[https://github.com/karthink/gptel-quick/blob/master/gptel-quick.el][gptel-quick]] package for sophisticated use of =gptel-request=

**** Get context for a phrase in any language
     #+begin_src emacs-lisp
       (defvar gjg/gptel-request-callback-done nil)
       (defun gjg/llm-explain (&optional myphrase)
         (let ((myphrase (cond
                          (myphrase myphrase)
                          ((region-active-p) (buffer-substring-no-properties (region-beginning) (region-end)))
                          (t (read-string "Phrase to expand with context: "))))
               (gjg/gptel-request-callback-done nil)
               (gptel-backend (alist-get "google-gemini" gptel--known-backends nil nil #'equal))
               (gptel-model 'gemini-flash-latest)
               (gptel-use-context 'system))
           (gptel-request
                        myphrase
                      :system "explain this phrase concisely, give examples of its use only if appropriate, historical context only if appropriate.  Reply only in the language of the phrase."
                      :callback (lambda (response info)
                                  (if (stringp response)
                                      (let ((posn (marker-position (plist-get info :position)))
                                            (buf (buffer-name (plist-get info :buffer))))
                                        (message "Heya - the LLM responded: check buffer *GORT*")
                                        (save-current-buffer
                                          (set-buffer (get-buffer-create "*GORT*"))
                                          (goto-char (point-max))
                                          (insert (format "\n%s\n" response))
                                          (setq gjg/gptel-request-callback-done t))
                                        response)
                                    (message "gptel-request failed with message: %s" (plist-get info :status))))
                      (while (not gjg/gptel-request-callback-done) (sleep-for 1))
                      )))


     #+end_src

*** Custom tools
    These are a collection of tools that can be provided to gptel

    Most of these tools use a separately defined callable function rather than a lambda form.  Partly because the functions may have use outside of gptel, partly because =gptel-make-tool= does not update once the tool slot has been created (as of <2025-03-23 Sun>)

**** Home and local category
***** Get weather forecast
     #+begin_src emacs-lisp :tangle no
       ;; (gptel-make-tool
       ;;  :name "weather_forecast"
       ;;  :function (lambda ()

       ;;              (let* ((buf (url-retrieve-synchronously "http://dataservice.accuweather.com/forecasts/v1/daily/5day/2201318?apikey=0xdeadbeefdeadbeef&details=true"))
       ;;                     (weather (if buf
       ;;                                  (with-current-buffer buf
       ;;                                    (buffer-substring-no-properties (point-min) (point-max)))
       ;;                                ("no weather forecast found"))))
       ;;                weather))
       ;;  :description "Get today's weather forecast for Conifer, Colorado."
       ;;  :category "home"
       ;;  :include t)

       (defun gjg/weather-com-forecast (&optional days location)
         "Get the weather forecast from weather.com.
       DAYS defaults to 1 (can be up to 3 for the free API).
       LOCATION defaults to zipcode 80433."
         (let ((apikey
                (encode-coding-string
                 (funcall
                  (plist-get
                   (car
                    (auth-source-search :host "api.weatherapi.com" :user "apikey" :require '(:secret)))
                   :secret))
                 'utf-8))
               (url "http://api.weatherapi.com/v1/forecast.json")
               (days (or days 1))
               (location (or location "80433")))
           (with-current-buffer (url-retrieve-synchronously (format "%s?key=%s&q=%s&days=%d&aqi=no&alerts=no" url apikey location days))
             ;; skip the headers
             (goto-char (point-min))
             (re-search-forward "^$" nil 'move)
             (delete-region (point-min) (point))
             (buffer-string ))))

       (gptel-make-tool
        ;; :function (lambda ()
        ;;             (let ((apikey
        ;;                    (encode-coding-string
        ;;                     (funcall
        ;;                      (plist-get
        ;;                       (car
        ;;                        (auth-source-search :host "api.weatherapi.com" :user "apikey" :require '(:secret)))
        ;;                       :secret))
        ;;                     'utf-8))))
        ;;             (url-retrieve-synchronously "http://api.weatherapi.com/v1/forecast.json?key=0xdeadbeefdeadbeef&q=80433&days=3&aqi=no&alerts=no"))
        :function #'gjg/weather-com-forecast
        :name "get_weather"
        :description "Get the current weather at home. Report on Fahrenheit and Imperical measures. Call with no arguments"
        :category "home"
        :include t)

       ;; :args (list '(:name "location"
       ;;                        :type string
       ;;                        :description "The city and state, e.g. San Francisco, CA")
       ;;             '(:name "unit"
       ;;                        :type string
       ;;                        :enum ["celsius" "farenheit"]
       ;;                        :description
       ;;                        "The unit of temperature, either 'celsius' or 'fahrenheit'. Defaults to fahrenheit"
       ;;                        :optional t))

#+end_src
***** Answer questions about Casona Ranona
#+begin_src emacs-lisp
  (gptel-make-tool
   :name "house_guide"
   :include t
   :function (lambda () "
  The house name is Casona Ranona, due to its occupants' love of frogs.

  Curly-headed Rozi and curmodgeonly Gortsleigh live there.

  Towels, sheets, pillow cases and bed linens are found in the upstairs guest bathroom.

  Home devices can be controlled both by Google Nest and Home Assistant.

  The guest wifi pass phrase is shmeedleypep321.

  The older black and white wooly mammoth cat is Molly, the blue-eyed friendly world-famous boy Siamese cat is Charlie.

  Whole house music is provided using Heos speakers - connect using DLNA or Heos app or Spotify Connect or Music Assistant or the Jellyfin server!
  ") ; TBD
   :description "Answer questions about the house / home / Casa Ranona including persons, cats, location of home items for guests.  Returns known facts about the home. Just pick out the facts relevant to the question you were asked. Called with no arguments"
   :category "home")
#+end_src
**** Prompts and settings to help with tool usage
     We need to reduce confusion / unnecessary complexity

     Including the results of tool calls in the context can confuse the model after a time (for example all the source code for a package)

     One thing to set and prompt for is =:include auto= - set this per tool, and indicate to the LLM that it has the choice of whether to include the tool results in future context

     Another thing I want to experiment with is telling the model to let me know when it would be helpful to "clear its mind" and remove certain content from the context.  I will then do so manually.  I suppose I could even add a tool called "ask-user-to-clear-some-context" with this explanation in the description

**** Reflection / Inspection / Coding category
     The "reflection" category includes references to using Emacs and Linux

***** Return README for an Emacs package
      #+begin_src emacs-lisp
        (defun gjg/extract-emacs-package-readme (package-name)
          "Extract and return the README file for package PACKAGE-NAME.
        This version attempts to robustly find the source directory for
        packages, including those managed by straight.el.
        Return =nil' if no README was found."
          (if (stringp package-name)
              (let* (;; 1. Get the path to the library file as Emacs knows it (e.g., .../straight/build/PKG/PKG.el)
                     (library-file-in-load-path (find-library-name package-name))

                     ;; 2. Get the canonical, true path to this library file.
                     ;; For straight.el, if library-file-in-load-path is a symlink like
                     ;; .../build/PKG/PKG.el -> .../repos/PKG/PKG.el,
                     ;; this will resolve to .../repos/PKG/PKG.el.
                     (true-library-file-path (when library-file-in-load-path
                                               (file-truename library-file-in-load-path)))

                     ;; 3. Get the directory containing the true library file.
                     ;; This should be the actual source directory (e.g., .../straight/repos/PKG/).
                     (package-source-dir (when true-library-file-path
                                           (file-name-directory true-library-file-path)))

                     ;; 4. Locate the README within this source directory using your helper.
                     ;; gjg/locate-readme-in-directory returns an absolute path.
                     (readme-full-path (when (and package-source-dir (file-directory-p package-source-dir))
                                         (gjg/locate-readme-in-directory package-source-dir))))

                (if readme-full-path
                    (with-temp-buffer
                      (goto-char (point-min))
                      (insert (format "README file for package %s (from directory %s):\n\n"
                                      package-name
                                      ;; Show the directory where the README was actually found
                                      (file-name-directory readme-full-path))) ; This is package-source-dir
                      (insert-file-contents readme-full-path)
                      (buffer-string))
                  (progn
                    ;; More detailed warning for debugging
                    (warn (format (concat "No README file found for package '%s'.\n"
                                          "  Searched in directory: %s\n"
                                          "  Library file in load-path: %s\n"
                                          "  Resolved true library file path: %s")
                                  package-name
                                  (or package-source-dir "unknown or not a directory")
                                  (or library-file-in-load-path "not found by find-library-name")
                                  (or true-library-file-path "could not be resolved by file-truename")))
                    nil)))
            (progn
              (warn "PACKAGE-NAME argument must be the package name as a string.")
              nil)))

        (gptel-make-tool
         :name "emacs_package_readme"
         :description "Return the README file for a package - please use this to understand what a package does prior to deciding whether to pull the package source code."
         :category "reflection"
         :include t
         :function #'gjg/extract-emacs-package-readme
         :args (list '(:name "package_name"
                             :type string
                             :description "Name of the Emacs package."
                             :optional nil)))
      #+end_src


***** Return source for an Emacs package
     Search for and return source code for an Emacs package.

     To stay within reasonable token constraints, return only the primary source code file unless all source files are requested by the LLM.

     #+begin_src emacs-lisp
       (defun gjg/extract-emacs-package-source (package &optional FULL)
         "Extract and return a simple structured text document with the primary source for package PACKAGE.
       If FULL is not nil, return all source files."
         (if (stringp package)
             (let* ((library-path (find-library-name package))
                    (all-elisp (directory-files (f-dirname library-path) t ".*\\.el\\(\\.gz\\)?$")))
               (with-temp-buffer
                 ;; run through the list of .el files
                 ;; start with the "primary" .el file, returned by =find-library-name=

                 (goto-char (point-min))
                 (insert (format "\n* file %s (primary)\n" library-path))
                 (insert "#+begin_src emacs-lisp\n")
                 (insert-file library-path)
                 (goto-char (point-max))
                 (insert "\n#+end_src\n")
                 (when FULL
                   (dolist (file (remove library-path all-elisp))
                   (insert (format "\n* file %s\n" file))
                   (insert "#+begin_src emacs-lisp\n")
                   (insert-file file)
                   (goto-char (point-max))
                   (insert "\n#+end_src\n")))
                 (buffer-string)))
           (warn "PACKAGE must be the package name as a string.")))

       (gptel-make-tool
        :name "emacs_package_source"
        :description "Fetch all source code for the given Emacs package, using `find-library'."
        :category "reflection"
        :include nil
        :function #'gjg/extract-emacs-package-source
        :args (list '(:name "package_name"
                            :type string
                            :description "Name of the Emacs package."
                            :optional nil)
                    '(:name "full_source"
                            :type boolean
                            :description "If true/t, return source from ALL source code files in the package, not just the primary source file. Let this default in most cases to save on tokens!"
                            :optional t)))
#+end_src
***** Return function source
     #+begin_src emacs-lisp
       (defun gjg/extract-function-source (function-name)
         "Extract and return the source code of a callable FUNCTION-NAME, if possible."
         (when (fboundp (intern function-name))
           (let ((source))
             (condition-case err
                 ;; `find-function-noselect' returns the buffer and position.
                 (let ((buf-pos (find-function-noselect (intern function-name))))
                   (when buf-pos
                     (let ((buffer (car buf-pos))
                           (pos (cdr buf-pos)))
                       (with-current-buffer buffer
                         (save-excursion
                           (goto-char pos)
                           (let ((start (point)))
                             ;; Move to the end of the function definition.
                             (end-of-defun)
                             ;; Extract source code.
                             (setq source (buffer-substring-no-properties start (point)))))))))
               (error
                ;; Handle errors gracefully by printing a message.
                (message "Error finding source for %s: %s" function-name (error-message-string err))))
             source)))

       ;; Usage example
       ;; (my-extract-callable-source 'your-function-name)

       (gptel-make-tool
        :name "emacs_function_source"
        :include t
        :function #'gjg/extract-function-source
        :description "Return source code for Emacs functions, be they written in Emacs Lisp (Elisp) or C"
        :category "reflection"
        :args (list '(:name "function_name"
                            :type string
                            :description "the function name"
                            :optional nil)))
#+end_src
***** Return Emacs variable value and documentation
        check this baby out (get 'symbol 'variable-documentation)
      #+begin_src emacs-lisp
        (get 'gptel-tools 'variable-documentation)

        (gptel-make-tool
         :name "emacs_variable_properties"
         :include t
         :function (lambda (variable)
                     (let ((variable (if (symbolp variable)
                                         variable
                                       (intern variable)
                                       )))
                       (if (boundp variable)
                           (symbol-plist variable)
                         (format "Variable %s is not bound" variable))))

         :description "Get properties on an Emacs variable.  Use this to get documentation string for variables, as well as more obscure properties such as safety as local variable etc."
         :category "reflection"
         :args (list '(:name "variable"
                             :type string
                             :description "the symbol")))
#+end_src

        To see all properties defined on a symbol:
        #+begin_src emacs-lisp  :tangle no
          (message (symbol-plist 'gptel--gemini-models))
#+end_src

***** Summarize all installed Info manuals
     Info manuals do not have a tightly prescribed structure for metadata, so just use the =dir= files for this purpose.

     #+begin_src emacs-lisp
       (defun gjg/get-info-manuals-with-description ()
         "Return text of all Info manuals with their simple descriptions.
       This is what you see when you evoke C-h i or run (info)."
         (with-temp-buffer
           (Info-insert-dir)
           (buffer-substring-no-properties (point-min) (point-max))))

       (gptel-make-tool
        :name "emacs_info_manuals"
        :include nil
        :function #'gjg/get-info-manuals-with-description
        :description "Get text showing all known Info manuals with their description. Format is human-readable manual name, info manual short file name in parens, description."
        :category "reflection")
#+end_src
***** Find list of man pages on system
     #+begin_src emacs-lisp
       (defun gjg/list-linux-man-pages (&optional s)
         "Return text showing installed Linux man pages with descriptions - optionally provide a substring match to limit the number of results."
         (let ((s (or s ""))
               (shell-command-dont-erase-buffer nil))
           (with-current-buffer "*man-pages*"
             (delete-region (point-min) (point-max))
             (shell-command (format "LANG=en_US.UTF-8 /usr/bin/man -k \"%s\"" s) t)
             (buffer-string)
             )))

       (gptel-make-tool
        :name "list_man_pages"
        :description "Return list of installed Linux man pages with descriptions - optionally provide a substring match to limit the number of results."
        :include nil
        :function #'gjg/list-linux-man-pages
        :category "reflection"
        :args (list '(:name "search_substring"
                            :type string
                            :optional t
                            :description "A substring to limit results of all man pages.  e.g. \"media\" or \"office\"")))
#+end_src
***** Cheat sheet for Org Mode synta
      As LLMs today in 2025+ can produce Org Mode easily, I like to circumvent gptel's markdown-to-org mode conversion
      #+begin_src emacs-lisp
        (gptel-make-tool
         :name "org_mode_cheatsheet"
         :description "Quick and easy to read cheat sheet for Org Mode syntax - refer to this whenever you start a project or session requiring org mode syntax production, and whenver you want to make use of advanced features."
         :include t
         :function (lambda ()
                     (with-temp-buffer
                       (insert-file-contents "~/projects/ai/AIPIHKAL/org-mode-syntax-cheat-sheet-for-llms.txt")
                       (buffer-string)))
         :category: "reflection")
#+end_src

**** Web / Internet / Online Research category
***** Search the web and read a web page

      Search and page read are placed into the same callable function which leverages =eww=

      I'm making 2 separate tools out of the one function to make it simpler for LLMs to decide how to use the tools.

      TODO: Think about switching this to use MCP to improve readability and precision for the LLM
         ref: [[https://github.com/karthink/gptel/issues/787]]


#+begin_src emacs-lisp
  (defcustom gjg/gptel-search-prefix
    (if (and (boundp 'eww-search-prefix) eww-search-prefix) eww-search-prefix "https://duckduckgo.com/html?q=")
    "Base URL used for searching the web using gptel tools.
  Falls back to duckduckgo if EWW is not loaded."
    :type 'string)

  (defun gjg/search-web (query)
    "Initiate a web search using the search engine defined in `gjg/gptel-search-prefix'."
    (condition-case err
        (let* ((url-with-query
                (url-encode-url (concat gjg/gptel-search-prefix query)))
               (content (shell-command-to-string
                         (format "lynx -dump -list_inline '%s'" url-with-query))))
          (format "Content pulled from %s\n\n%s" query content))
      (warning (format "Error accessing %s: %s" query (error-message-string err)))))


  (defun gjg/read-web (url)
    "Pull in a web page with plain text and links."
    (condition-case err
        (let ((content (shell-command-to-string
                         (format "lynx -dump -list_inline %s" url))))
          (format "Content pulled from %s\n\n%s" url content))
      (warning (format "Error accessing %s: %s" url (error-message-string err)))))


  (gptel-make-tool
   :name "search_web"
   :function #'gjg/search-web
   :description "Search the web"
   :include t
   :category "web"
   :args (list `(:name "query"
                       :type string
                       :description ,(format "Search terms / string to search on the web using %s" gjg/gptel-search-prefix))))

  (gptel-make-tool
   :name "read_webpage"
   :function #'gjg/read-web
   :description "Read the content of a URL"
   :include t
   :category "web"
   :args (list '(:name "url"
                       :type string
                       :description "URL to read")))
#+end_src
***** Open a web page for the putative human
** Agentic work with agent-shell
   + [[https://xenodium.com/introducing-agent-shell][Introducing Emacs agent-shell (powered by ACP) ≫ xenodium.com]]
   + [[https://github.com/xenodium/agent-shell?tab=readme-ov-file][xenodium/agent-shell ≫ github.com]]

   Install comint helping dependency shell-maker, then acp and agent-shell
   #+begin_src emacs-lisp :tangle no
     (add-to-list 'exec-path (expand-file-name "~/.nvm/versions/node/v24.7.0/bin"))

     (use-package shell-maker :straight t)

     (straight-use-package
      '(acp :type git :host github :repo "xenodium/acp.el"))

     (straight-use-package
      '(agent-shell :type git :host github :repo "xenodium/agent-shell"))

     (setq agent-shell-anthropic-key
           (gjg/authinfo-secret "api.anthropic.com"))

     (setq agent-shell-google-key
           (gjg/authinfo-secret "generativelanguage.googleapis.com"))

     (setq agent-shell-openai-key
           (gjg/authinfo-secret "api.openai.com"))

     (require 'agent-shell)
   #+end_src
** ECA - Emacs AI Code/Coding Assistant
    #+begin_src emacs-lisp :tangle no
      (straight-use-package
       '(eca :type git :host github :repo "editor-code-assistant/eca-emacs"
                     :fork (:host github :branch "master" :repo "gregoryg/eca-emacs")))
    #+end_src
